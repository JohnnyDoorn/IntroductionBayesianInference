<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.340">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>A Brief Introduction to Bayesian Inference - 5&nbsp; More Bayesian Analyses</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./06-exercises.html" rel="next">
<link href="./04-beer.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./05-more-tests.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">More Bayesian Analyses</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">A Brief Introduction to Bayesian Inference</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">The Lady Tasting Tea</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">What is a Model?</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">How do Models Estimate?</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-beer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">The Beer Tasting</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-more-tests.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">More Bayesian Analyses</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Exercises</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-anova.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">ANOVA</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-bayesian-ttest" id="toc-sec-bayesian-ttest" class="nav-link active" data-scroll-target="#sec-bayesian-ttest"><span class="header-section-number">5.1</span> The Bayesian T-Test</a>
  <ul class="collapse">
  <li><a href="#sec-prior-ttest" id="toc-sec-prior-ttest" class="nav-link" data-scroll-target="#sec-prior-ttest"><span class="header-section-number">5.1.1</span> Prior Distribution</a></li>
  <li><a href="#predictive-updating-factor" id="toc-predictive-updating-factor" class="nav-link" data-scroll-target="#predictive-updating-factor"><span class="header-section-number">5.1.2</span> Predictive Updating Factor</a></li>
  <li><a href="#posterior-distribution-bayes-factor" id="toc-posterior-distribution-bayes-factor" class="nav-link" data-scroll-target="#posterior-distribution-bayes-factor"><span class="header-section-number">5.1.3</span> Posterior Distribution &amp; Bayes Factor</a></li>
  </ul></li>
  <li><a href="#the-bayesian-correlation" id="toc-the-bayesian-correlation" class="nav-link" data-scroll-target="#the-bayesian-correlation"><span class="header-section-number">5.2</span> The Bayesian Correlation</a>
  <ul class="collapse">
  <li><a href="#prior-distribution" id="toc-prior-distribution" class="nav-link" data-scroll-target="#prior-distribution"><span class="header-section-number">5.2.1</span> Prior Distribution</a></li>
  <li><a href="#predictive-updating-factor-1" id="toc-predictive-updating-factor-1" class="nav-link" data-scroll-target="#predictive-updating-factor-1"><span class="header-section-number">5.2.2</span> Predictive Updating Factor</a></li>
  <li><a href="#posterior-distribution-bayes-factor-1" id="toc-posterior-distribution-bayes-factor-1" class="nav-link" data-scroll-target="#posterior-distribution-bayes-factor-1"><span class="header-section-number">5.2.3</span> Posterior Distribution &amp; Bayes Factor</a></li>
  </ul></li>
  <li><a href="#concluding-thoughts" id="toc-concluding-thoughts" class="nav-link" data-scroll-target="#concluding-thoughts"><span class="header-section-number">5.3</span> Concluding Thoughts</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="chap-more-models" class="quarto-section-identifier"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">More Bayesian Analyses</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>All of the concepts that were discussed in the previous chapters can also be applied to Bayesian analyses for other types of research questions, such as correlations or differences in means (i.e., the <span class="math inline">\(t\)</span>-test). In the current chapter, we will explore these tests using the same beer-tasting data set. Besides measuring whether participants identified the correct beer, we also recorded how tasty they found each of the two beers, which we can use to answer the following two questions:</p>
<ul>
<li>Do people find alcoholic beer tastier?</li>
<li>Is there an association between tastiness ratings?</li>
</ul>
<section id="sec-bayesian-ttest" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="sec-bayesian-ttest"><span class="header-section-number">5.1</span> The Bayesian T-Test</h2>
<p>The first question, “do people find alcoholic beer tastier?”, concerns the difference between means. Since each participant tasted the alcoholic and non-alcoholic beer, this was measured within subjects, and so a within subjects <span class="math inline">\(t\)</span>-test is required. For Bayesian <span class="math inline">\(t\)</span>-tests, the parameter of interest is denoted <span class="math inline">\(\delta\)</span> (“delta”). This parameter is a standardized difference between two means, and is formally known as “Cohen’s <em>d</em>”, a very common <a href="https://en.wikipedia.org/wiki/Effect_size">effect size</a> in psychology.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> When doing inferential statistics, we can either estimate the magnitude of this effect size, conduct model comparison, or both. In the sections below, the Bayesian ingredients are described for the <span class="math inline">\(t\)</span>-test.</p>
<!-- ```{r jasp-screenshot-binomial-test, echo = FALSE, fig.cap = "Screenshot of the options for the Bayesian binomial test in JASP.", fig.align='center',  out.width= '100%'} -->
<!-- knitr::include_graphics("Figures/binomTestJASPpanel2022.png", dpi=120)  -->
<!-- ``` -->
<section id="sec-prior-ttest" class="level3" data-number="5.1.1">
<h3 data-number="5.1.1" class="anchored" data-anchor-id="sec-prior-ttest"><span class="header-section-number">5.1.1</span> Prior Distribution</h3>
<p>The prior distribution is always defined on the same domain as the parameter of interest. For the proportion, this was the convenient domain of [0, 1], and so allowed the use of the beta distribution, and the possibility to use the uniform distribution as the uninformed prior distribution. The domain of <span class="math inline">\(\delta\)</span> instead goes from <span class="math inline">\(-\infty\)</span> to <span class="math inline">\(\infty\)</span>, so its prior distribution has to match that domain. For a null hypothesis this does not matter so much, since the null hypothesis generally posits a single value (e.g., 0, stating there is no difference between the groups). However, for the alternative hypothesis it becomes tricky now to have a uniform distribution on the whole domain of <span class="math inline">\(\delta\)</span>. Since the domain is infinitely big, the density of a uniform distribution between <span class="math inline">\(-\infty\)</span> and <span class="math inline">\(\infty\)</span> would need to be infinitely small, which is not very practical. Instead, what is generally done is to apply a probability distribution that is spread out a little less (although still a lot more than a point null hypothesis). One such distribution is the <a href="https://en.wikipedia.org/wiki/Cauchy_distribution">Cauchy distribution</a>, which is a <span class="math inline">\(t\)</span> distribution with a single degree of freedom. The width of the Cauchy distribution is determined by the <strong>Cauchy scale parameter</strong>. Below, several examples are given:</p>
<div class="cell" data-layout-align="center" data-hash="05-more-tests_cache/html/fig-three-cauchy-dists_2a165c910d10d4953196f05c8fad9cbe">
<div class="cell-output-display">
<div id="fig-three-cauchy-dists" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="05-more-tests_files/figure-html/fig-three-cauchy-dists-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;5.1: Three different Cauchy distributions. Each of these can be used as a model for the difference between two groups, and each of these has a (slightly) different theoretical implication.</figcaption>
</figure>
</div>
</div>
</div>
<p>Just as before, these distributions can serve as a statement about the population parameter. Also just as before, each of these models make predictions about the world, and will have a certain quality of their prediction: how well did they predict the data? We can look at how well they did, and compare it to how well the null model (which went “all-in” on 0) predicted the data. Before we do that, we can first take a look at how these models will learn from the data: how is this prior knowledge updated to form posterior knowledge?</p>
</section>
<section id="predictive-updating-factor" class="level3" data-number="5.1.2">
<h3 data-number="5.1.2" class="anchored" data-anchor-id="predictive-updating-factor"><span class="header-section-number">5.1.2</span> Predictive Updating Factor</h3>
<p>The Bayesian belief updating again follows the general form presented in <a href="03-estimation.html"><span>Chapter&nbsp;3</span></a>. Again, we update the prior knowledge with information from the data. In the case of the beer tasting experiment, there was an observed effect size of <span class="math inline">\(0.714\)</span> (for more descriptives see <a href="#fig-beer-tastiness-descriptives">Figure&nbsp;<span>5.2</span></a> below).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-beer-tastiness-descriptives" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Figures/DescriptivesBeerTastiness.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;5.2: The descriptive statistics for the tastiness ratings for both the alcoholic and non-alcoholic beers. The observed mean for the alcoholic beer is higher than for the non-alcoholic beer, but how much evidence is there in favor of this difference?</figcaption>
</figure>
</div>
</div>
</div>
<p>The predictive updating factor quantifies how well each of the values in the model predicted the observed effect of <span class="math inline">\(0.714\)</span> (as quantified by the likelihood), compared to how well the model did on average (as quantified by the marginal likelihood). <a href="#fig-beer-t-test-likelihood">Figure&nbsp;<span>5.3</span></a> below shows the likelihood of the observed data for various values of <span class="math inline">\(\delta\)</span>. The purple bar indicates the marginal likelihood for the one-sided Cauchy model (scale = 0.707), to show which values in that model will receive a boost in plausibility. Remember that it is the likelihood function that is the same for any model, but that the marginal likelihood of that model will differ (based on its predictions).</p>
<div class="cell" data-layout-align="center" data-hash="05-more-tests_cache/html/fig-beer-t-test-likelihood_8ea55baf004bd13862027928e08d65e8">
<div class="cell-output-display">
<div id="fig-beer-t-test-likelihood" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="05-more-tests_files/figure-html/fig-beer-t-test-likelihood-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;5.3: The likelihood of the observed data, for various values of delta. The higher the likelihood, the better that value predicted the data.</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="posterior-distribution-bayes-factor" class="level3" data-number="5.1.3">
<h3 data-number="5.1.3" class="anchored" data-anchor-id="posterior-distribution-bayes-factor"><span class="header-section-number">5.1.3</span> Posterior Distribution &amp; Bayes Factor</h3>
<p>Values in the model that predicted the data well, will see in increase in density when comparing prior to posterior distribution. <a href="#fig-beer-t-test-likelihood">Figure&nbsp;<span>5.3</span></a> shows that values between 0.5 and 1 will receive a boost in plausibility. <a href="#fig-beer-tastiness-t-test-posterior">Figure&nbsp;<span>5.4</span></a> below shows the JASP-results for the Bayesian <span class="math inline">\(t\)</span>-test, using a one-sided alternative hypothesis to test the hypothesis that people like the alcoholic beer more than the non-alcoholic beer. The posterior distribution is fairly concentrated between <span class="math inline">\(0.5\)</span> and <span class="math inline">\(1\)</span>, with a 95% credible interval from 0.398 to 0.978, so that is already some evidence that the tastiness ratings differ between the two beers. In addition, the Bayes factor comparing the predictions of the two hypotheses shows that the data are 22200 times more likely under the alternative hypothesis <span class="math inline">\(\mathcal{H}_{+}\)</span> than under <span class="math inline">\(\mathcal{H}_{0}\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-beer-tastiness-t-test-posterior" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Figures/TTestBeerTastiness.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;5.4: The results of the Bayesian paired samples t-test on the tastiness ratings. The bayes factor comparing the predictions of the one-sided, positive, alternative hypothesis to the null hypothesis is very strongly in favor of the alternative hypothesis: the data are 22200 times more likely under the alternative hypothesis than under the null hypothesis.</figcaption>
</figure>
</div>
</div>
</div>
<section id="bayes-factor-robustness" class="level4" data-number="5.1.3.1">
<h4 data-number="5.1.3.1" class="anchored" data-anchor-id="bayes-factor-robustness"><span class="header-section-number">5.1.3.1</span> Bayes Factor Robustness</h4>
<p>Specifying the prior distribution is a fairly subjective endeavor in Bayesian analyses. For most analyses, there exist some guiding principles for choosing an uninformative prior distribution, but it is still worth investigaing how robust the obtained Bayes factor is to different prior specifications. Since the Bayes factor compares the predictions of two models, changing the prior distribution changes the model’s prediction and therefore also alters the Bayes factor. To analyze to what extent this happens, a <strong>robustness check</strong> can be conducted, where different prior specifications are explored.</p>
<p>For the <span class="math inline">\(t\)</span>-test, where the Cauchy prior distribution is governed by a single shape parameter (its scale), a convenient plot can be constructed, where the Bayes factor is shown as a function of the shape parameter. <a href="#fig-beer-tastiness-t-test-robustness">Figure&nbsp;<span>5.5</span></a> shows such a plot. Here we can see that there is quite strong evidence in favor of <span class="math inline">\(\mathcal{H}_{+}\)</span> for almost all Cauchy prior widths in the graph (i.e., the line is relatively flat). Only for extreme values of the Cauchy scale parameter (around <span class="math inline">\(0.05\)</span>), does the evidence in favor of <span class="math inline">\(\mathcal{H}_{+}\)</span> decrease towards 1. This is a logical consequence of changing the prior distribution: the prior distribution formalizes a model’s predictions, and if the prior distribution becomes extremely narrow, it starts resembling the null model. For a Cauchy width of, say, <span class="math inline">\(0.01\)</span>, the alternative and null model make very similar predictions, and so the Bayes factor will be around 1. In the context of a robustness check, we can ignore such extreme specifications. We generally aim to detect whether, for instance, the Bayes factor with a width of 1 qualitatively differs from the Bayes factor with a width of 0.5. If that is the case, then our result is perhaps not so reliable, and we would need more data to create a more robust result.</p>
<!-- In reality, what generally happens is people use the default/uninformed options (e.g., uniform for proportion, Cauchy with scale 0.707 for $t$-test), and follow up this analysis with a robustness check. -->
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-beer-tastiness-t-test-robustness" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Figures/TTestBeerTastinessRobustness.png" class="img-fluid figure-img" style="width:90.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;5.5: A robustness analysis of the Bayesian t-test. Here we explore how much the Bayes factor changes, as a result of using a different value for the Cauchy scale parameter. Generally, the flatter the line, the more robust the Bayes factor is to different prior specifications.</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="the-bayesian-correlation" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="the-bayesian-correlation"><span class="header-section-number">5.2</span> The Bayesian Correlation</h2>
<p>In addition to testing whether there is a difference in tastiness ratings, we can also analyze whether there is an association between the ratings of the two beers: are people who rate the alcoholic beer as tasty, more inclined to also rate the non-alcoholic beer as tasty? In other words, are there people who just really like Weihenstephaner (and give both beers high scores), and people who do not (and give both beers low scores)?</p>
<p>In order to do so, we can conduct a Bayesian correlation analysis. We will again be using all the key ingredients from the previous chapters. We will start with some prior distribution, then update this with the information in the observed data, to form posterior knowledge about the population correlation <span class="math inline">\(\rho\)</span> (“rho”). Additionally, we can conduct a hypothesis test, where we compare a model that states no association between the ratings, and a model that states that there is some positive association.</p>
<p>To conduct a Bayesian correlation test in JASP, you can select (after loading the data) “Regression”, then “Bayesian correlation”. This presents the correlation analysis for several variables. To obtain more results, you can go to “Plot Individual Pairs”, where JASP allows a more thorough analysis of individual pairs of variables. See <a href="#fig-beer-tastiness-correlation-JASP">Figure&nbsp;<span>5.6</span></a> for a screenshot of the current analysis.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-beer-tastiness-correlation-JASP" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Figures/correlationTestJASPpanel2022.png" class="img-fluid figure-img" style="width:90.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;5.6: The JASP user interface for the Bayesian correlation analysis. To enable more analysis options, the “Plot Individual Pairs” tab can be used.</figcaption>
</figure>
</div>
</div>
</div>
<section id="prior-distribution" class="level3" data-number="5.2.1">
<h3 data-number="5.2.1" class="anchored" data-anchor-id="prior-distribution"><span class="header-section-number">5.2.1</span> Prior Distribution</h3>
<p>The domain of the correlation is <span class="math inline">\([-1, 1]\)</span>, so we need a prior distribution that matches that domain. In this case, we can take the beta distribution from before, and stretch its domain to create the <strong>stretched beta distribution</strong>. While before, the values of a and b can be specified individually, for the stretched beta distribution we only set a single value for both a and b: the prior width. The width is the inverse of <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>: a width equal to 0.5 means a stretched beta distribution with <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> equal to <span class="math inline">\(1 / 0.5 = 2\)</span>. A width equal to 1 means a stretched beta distribution with <span class="math inline">\(a = b = 1\)</span>. <a href="#fig-three-stretched-beta-dists">Figure&nbsp;<span>5.7</span></a> shows three versions of the stretched beta distribution - additionally showing that these distributions can also be one-sided (i.e., only considering negative or positive correlations).</p>
<div class="cell" data-layout-align="center" data-hash="05-more-tests_cache/html/fig-three-stretched-beta-dists_826590e00a5885a00acd534360054595">
<div class="cell-output-display">
<div id="fig-three-stretched-beta-dists" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="05-more-tests_files/figure-html/fig-three-stretched-beta-dists-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;5.7: Three different stretched beta distributions. Each of these can be used as a model for the correlation, and each of these has a (slightly) different theoretical implication.</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="predictive-updating-factor-1" class="level3" data-number="5.2.2">
<h3 data-number="5.2.2" class="anchored" data-anchor-id="predictive-updating-factor-1"><span class="header-section-number">5.2.2</span> Predictive Updating Factor</h3>
<p>The observed correlation <span class="math inline">\(r\)</span> is equal to <span class="math inline">\(0.1034\)</span>, and we can look at how likely this result is for various values of the population correlation <span class="math inline">\(\rho\)</span>. <a href="#fig-beer-correlation-likelihood">Figure&nbsp;<span>5.8</span></a> shows the likelihood function. The likelihood of observing a correlation of <span class="math inline">\(0.1\)</span> is highest when the population correlation is in fact equal to <span class="math inline">\(0.1\)</span>. As before, the likelihood illustrates which values of <span class="math inline">\(\rho\)</span> have a good match (i.e., a good prediction) with the observed data.</p>
<p>To see which values in the model predicted the data better than average, we can look at the marginal likelihood for that model. The purple bar in <a href="#fig-beer-correlation-likelihood">Figure&nbsp;<span>5.8</span></a> shows the marginal likelihood for the two-sided model (prior width = 1). We use the marginal likelihood to see which values of <span class="math inline">\(\rho\)</span> deserve a boost in plausibilty, and later we will compare marginal likelihoods of different models to obtain a Bayes factor.</p>
<div class="cell" data-layout-align="center" data-hash="05-more-tests_cache/html/fig-beer-correlation-likelihood_d5806a582107e0c0362b2795a10ad775">
<div class="cell-output-display">
<div id="fig-beer-correlation-likelihood" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="05-more-tests_files/figure-html/fig-beer-correlation-likelihood-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;5.8: The likelihood of the observed data, for various values of rho. The higher the likelihood, the better that value predicted the data. The likelihood is the highest for the observed correlation (0.1).</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="posterior-distribution-bayes-factor-1" class="level3" data-number="5.2.3">
<h3 data-number="5.2.3" class="anchored" data-anchor-id="posterior-distribution-bayes-factor-1"><span class="header-section-number">5.2.3</span> Posterior Distribution &amp; Bayes Factor</h3>
<p>The updated beliefs about <span class="math inline">\(\rho\)</span> are shown in <a href="#fig-beer-tastiness-correlation-posterior">Figure&nbsp;<span>5.9</span></a>. In order to test whether there is an association, we can look at the Bayes factor. Here, we have found moderate evidence in favor of the null hypothesis: the data are 4.5 times more likely under the null model, compared to the alternative model. This highlights an important feature of Bayesian hypothesis testing: since we concretely quantify what both models predict, we can actually obtain evidence <em>in favor</em> of the null hypothesis. This means we can distinguish between <strong>absence of evidence</strong> and <strong>evidence of absence</strong>. The former means that there is just no evidence to conclude that there is an association, while the latter means that we have found evidence for the lack of an association. In terms of Bayes factors, absence of evidence occurs when we observe a Bayes factor close to 1 (no evidence either way), while evidence of absence occurs when we observe <span class="math inline">\(\text{BF}_{01} &gt; 1\)</span>. The evidence in favor of the null also highlights the Savage-Dickey density ratio: <span class="math inline">\(\rho\)</span> being equal to 0 has become more plausible as a result of the data (its posterior density is greater than its prior density). This means that models that bet a lot of money on this value (such as the null model) will do very well in model comparisons.</p>
<p>In terms of parameter estimation, we can look at the posterior median and credible interval. The posterior median is quite close to 0, and the 95% credible interval ranges from <span class="math inline">\(-0.158\)</span> to <span class="math inline">\(0.3436\)</span>: under the two-sided uniform model, there is a 95% probability that the true value of <span class="math inline">\(\rho\)</span> lies in that interval.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-beer-tastiness-correlation-posterior" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Figures/CorrelationTestPosterior.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;5.9: The posterior distribution of rho, based on a two-sided uniform prior distribution. Under this model, there is a 95% probability that rho is between -0.155 and 0.331. There is moderate evidence in favor of the null hypothesis: the data are 4.5 times more likely under the null model, compared to the alternative model.</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="concluding-thoughts" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="concluding-thoughts"><span class="header-section-number">5.3</span> Concluding Thoughts</h2>
<p>In this chapter, we have seen the Bayesian concepts from the previous chapters, but then applied to different research questions/parameters. Instead of models making statements about <span class="math inline">\(\theta\)</span>, we looked at parameters that govern a difference between means (<span class="math inline">\(\delta\)</span>) or an association (<span class="math inline">\(\rho\)</span>). With a different parameter comes a different type of prior distribution, since the prior distribution matches the domain of the parameter. However, everything that follows is exactly the same as for the binomial analysis: the prior distribution is updated using the (marginal) likelihood to form posterior beliefs. We can compare marginal likelihoods of different models to obtain a Bayes factor. To investigate the robustness of the Bayes factor to the choice of prior distribution, a robustness check can be conducted.</p>
<p>Lastly, the Bayes factor helps to distinguish between “evidence of absence” and “absence of evidence”. This is quite informative, since they have two distinct meanings. Traditionally in psychology, journals are mostly interested in “non-null” effects, since these are deemed a lot sexier (and also because the p-value cannot easily distinguish between EoA and AoE). This results in some stress for empirical researchers: what if you spent 2 years of your PhD project collecting data, and you do not find your hypothesized effect and therefore cannot publish? Being able to quantify evidence in favor of the null hypothesis can hopefully create a scientific discourse that is more inclusive towards null-findings.</p>


</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>There are many more effect sizes that can quantify a difference in means, but for simplicity’s sake we focus on Cohen’s <em>d</em> here.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./04-beer.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">The Beer Tasting</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./06-exercises.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Exercises</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>